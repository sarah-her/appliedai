{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "801a5788",
      "metadata": {
        "id": "801a5788"
      },
      "source": [
        "### GARCH Modeling of Temperature in Los Angeles Returns\n",
        "\n",
        "\n",
        "In this notebook, we explore how volatility in city temperature — specifically for teh city of Los Angeles — can be modeled and forecasted using two important time series approaches:\n",
        "\n",
        "- GARCH(1,1): A classic model where today's volatility depends on past shocks and past volatility.\n",
        "- EGARCH(1,1): An extended version that captures asymmetric behavior — allowing for different impacts depending on whether temperature changes are positive or negative.\n",
        "\n",
        "Our goal is to evaluate how well these models describe the risk or variability in temperature behavior, how they perform in forecasting future volatility, and how we can use them to estimate extreme outcomes or risk measures such as Value at Risk (VaR) — repurposed in this context as the probability of unusually large temperature swings.\n",
        "\n",
        "While GARCH models are primarily used in financial econometrics, they are increasingly applied to climate and environmental data, where variability and clustering of shocks are also common. One key insight from GARCH modeling is that volatility is not constant — periods of stable weather can be followed by clusters of high variability (e.g., during seasonal transitions or unusual weather patterns).\n",
        "\n",
        "Another behavioral pattern we explore is asymmetry in temperature changes: Are sudden drops (cold snaps) associated with more volatility than sudden warm-ups? This is similar to the idea in financial markets where “bad news” often triggers more extreme reactions than “good news.”\n",
        "\n",
        "\n",
        "### GARCH(1,1)\n",
        "\n",
        "The GARCH(p, q) framework captures this dynamic by modeling the conditional variance (volatility) at any given time as a function of two things:\n",
        "\n",
        "- Past squared shocks (errors) — how surprising or extreme previous changes were\n",
        "- Past variances — how variable the recent temperature changes have been\n",
        "\n",
        "Let us denote the return equation:\n",
        "\n",
        "$$r_t = \\mu + \\varepsilon_t$$\n",
        "\n",
        "Where:\n",
        "\n",
        "- $r_t$ is daily temperature change (or return) at time $t$ (e.g., the change in temperature or log-change from the previous day)\n",
        "- $\\mu$ is the conditional mean of temperature returns (often assumed constant or modeled separately)  \n",
        "- $\\varepsilon_t$ is the innovation or shock at time $t$ — the unpredictable component of the process, representing the deviation from expected behavior\n",
        "\n",
        "We also model the shock $\\varepsilon_t$ as:\n",
        "\n",
        "$$\\varepsilon_t = \\sigma_t z_t$$\n",
        "\n",
        "Where:\n",
        "\n",
        "- $\\sigma_t$ is the conditional standard deviation (i.e., volatility) at time $t$  \n",
        "- $z_t$ is a white noise process (typically $z_t \\sim \\text{i.i.d. } \\mathcal{N}(0, 1)$ or another standardized distribution)\n",
        "\n",
        "This means:\n",
        "- $\\varepsilon_t$ is the return shock scaled by the volatility at that time  \n",
        "- The volatility $\\sigma_t$ varies over time, which is the key insight in GARCH modeling\n",
        "\n",
        "\n",
        "GARCH(1,1) Equation:\n",
        "\n",
        "$$\\sigma^2_t = \\omega + \\alpha \\times \\varepsilon^2_{t-1} + \\beta \\times \\sigma^2_{t-1}$$\n",
        "\n",
        "\n",
        "Where:\n",
        "- $\\sigma_t^2$ is the conditional variance of daily temperature changes at time $t$, given past information up to $t-1$  \n",
        "- $\\varepsilon_{t-1}^2$: the squared innovation (or shock) from time $t-1$\n",
        "- $\\omega > 0$ is the long-run or baseline level of variance. It ensures that volatility remains strictly positive even when past shocks are negligible. A larger $\\omega$ implies a higher unconditional variance, all else equal.\n",
        "- $\\alpha \\geq 0$ is the ARCH parameter, which measures the short-term impact of new information on volatility. Specifically, it quantifies how sensitive today's variance is to the magnitude of the most recent shock / innovation. A higher $\\alpha$ implies that volatility reacts more strongly to recent changes.\n",
        "- $\\beta \\geq 0$ is the GARCH parameter, capturing the persistence of past volatility. It determines how much of the previous day's variance carries forward to the current period. A high $\\beta$ indicates long memory in volatility — meaning shocks decay slowly over time.\n",
        "\n",
        "We assume:\n",
        "- $\\omega, \\alpha, \\beta \\geq 0$\n",
        "- $\\alpha + \\beta < 1$\n",
        "\n",
        "In the long term, we know that $\\sigma = \\omega / (1-\\alpha - \\beta)$\n",
        "\n",
        "\n",
        "### EGARCH(1,1) for asymmetric volatility\n",
        "\n",
        "The conditional variance in the Exponential GARCH (EGARCH) model is defined as:\n",
        "\n",
        "$$\n",
        "\\log(\\sigma_t^2) = \\omega + \\beta \\log(\\sigma_{t-1}^2) + \\alpha \\left| \\frac{\\varepsilon_{t-1}}{\\sigma_{t-1}} \\right| + \\gamma \\frac{\\varepsilon_{t-1}}{\\sigma_{t-1}}\n",
        "$$\n",
        "\n",
        "This formulation models the log of variance, which ensures that $\\sigma_t^2$ is always positive, without requiring non-negativity constraints on the parameters.\n",
        "\n",
        "The EGARCH model includes an asymmetric term through the parameter $\\gamma$, allowing for different volatility responses to positive and negative swings. Specifically:\n",
        "\n",
        "- The term $\\left| \\frac{\\varepsilon_{t-1}}{\\sigma_{t-1}} \\right|$ captures the magnitude of the standardized shock.\n",
        "- The term $\\frac{\\varepsilon_{t-1}}{\\sigma_{t-1}}$ captures its sign and direction.\n",
        "\n",
        "$\\gamma$: captures asymmetric effect\n",
        "\n",
        "- If $\\gamma < 0$: negative shocks (e.g., sudden temperature drops) increase volatility more than positive ones\n",
        "- If $\\gamma > 0$: positive shocks increase volatility more\n",
        "\n",
        "$\\beta$: volatility persistence\n",
        "\n",
        "In this assignment, we'll apply both models to historical daily temperature data for San Diego, compute the conditional volatility, and evaluate the ability of these models to forecast future variability and extreme events.\n",
        "\n",
        "We'll also compute Value at Risk (VaR) estimates — here, interpreted as thresholds for extreme temperature swings, to identify the likelihood of experiencing large temperature movements over time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ba082b21",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ba082b21",
        "outputId": "dd0a4bf6-40f8-40b7-b857-153a01f7a94e"
      },
      "outputs": [],
      "source": [
        "### INSTALL PACKAGES IF NEEDED\n",
        "#!pip install pandas-datareader\n",
        "#!pip install arch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "00222dc8",
      "metadata": {
        "id": "00222dc8"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from arch import arch_model\n",
        "from statsmodels.graphics.tsaplots import plot_acf\n",
        "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
        "from scipy.stats import t\n",
        "import pandas_datareader.data as web"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "60c06562",
      "metadata": {
        "id": "60c06562"
      },
      "source": [
        "### Step 1: Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "18fe45c2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "18fe45c2",
        "outputId": "811a483c-e3ac-4778-af7f-685522206b9e"
      },
      "outputs": [],
      "source": [
        "# Get Los Angeles Temperature\n",
        "data = ### Bring in the 'date' and 'Los Angeles' columns from 'temperature.csv'\n",
        "\n",
        "# Compute log changes\n",
        "data['Change'] = np.log(data[____] / data[____].shift(1)) * 100 ###FILL IN BLANKS\n",
        "returns = data['Change'].dropna()\n",
        "\n",
        "# Plot ###FILL IN BLANKS BELOW\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(___)\n",
        "plt.title(___)\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Change (%)')\n",
        "plt.grid(True)\n",
        "plt.____()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1c433f4b",
      "metadata": {
        "id": "1c433f4b"
      },
      "source": [
        "### Step 2: Fit GARCH(1,1) Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b4ecc2ea",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b4ecc2ea",
        "outputId": "50e51652-2752-4877-a943-2c9e38e04037"
      },
      "outputs": [],
      "source": [
        "model1 = arch_model(returns, vol='Garch', p=1, q=1, mean='Constant', dist='normal')\n",
        "res1 = model1.fit(disp='off')\n",
        "print(___) ###FILL IN THE BLANK TO PRINT THE SUMMARY"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1c634ee1",
      "metadata": {
        "id": "1c634ee1"
      },
      "source": [
        "Using the above analysis, elaborate on the following, including signficances and implication:\n",
        "- Mean Equation\n",
        "\n",
        "- Volatility Equation:\n",
        "  - ω (long-run volatility)\n",
        "  - α₁ (reaction to shocks)\n",
        "  - β₁ (volatility persistence)\n",
        "  - α₁ + β₁\n",
        "\n",
        "- Distribution\n",
        "\n",
        "- Log-Likelihood\n",
        "\n",
        "- AIC (Akaike Information Criterion)\n",
        "- BIC (Bayesian Information Criterion)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "11553e54",
      "metadata": {
        "id": "11553e54"
      },
      "source": [
        "### Step 3: Fit EGARCH(1,1) Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "85e43217",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "85e43217",
        "outputId": "8e630e3f-a0a2-481b-cc0e-9005b240eac5"
      },
      "outputs": [],
      "source": [
        "model2 = ###COMPLETE THIS LINE\n",
        "res2 = model2.fit(disp='off')\n",
        "print(____)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e99d9091",
      "metadata": {
        "id": "e99d9091"
      },
      "source": [
        "Using the above analysis, elaborate on the following, including signficances and implication:\n",
        "- Mean Equation\n",
        "\n",
        "- Volatility Equation:\n",
        "  - ω (long-run volatility)\n",
        "  - α₁ (reaction to shocks)\n",
        "  - β₁ (volatility persistence)\n",
        "  - α₁ + β₁\n",
        "\n",
        "- Distribution\n",
        "\n",
        "- Degrees of Freedom\n",
        "\n",
        "- Log-Likelihood\n",
        "\n",
        "- AIC (Akaike Information Criterion)\n",
        "- BIC (Bayesian Information Criterion)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1f903638",
      "metadata": {
        "id": "1f903638"
      },
      "source": [
        "### Step 4: Compare AIC/BIC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "462c2f16",
      "metadata": {
        "id": "462c2f16",
        "outputId": "f2c4acc5-1702-499d-b828-462f62ea1cd9"
      },
      "outputs": [],
      "source": [
        "print(\"GARCH AIC:\", res1.aic, \"| BIC:\", res1.bic)\n",
        "print(\"EGARCH AIC:\", res2.aic, \"| BIC:\", res2.bic)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "12b02aa0",
      "metadata": {
        "id": "12b02aa0"
      },
      "source": [
        "What does the above analysis tell us with respect to model fit and complevity?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a54cfedf",
      "metadata": {
        "id": "a54cfedf"
      },
      "source": [
        "### Step 5: Residual Diagnostics - ACF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9857a6b6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        },
        "id": "9857a6b6",
        "outputId": "6d632831-aac8-4707-c89d-7186eb2e01f1"
      },
      "outputs": [],
      "source": [
        "plot_acf(____) ###FILL IN THE BLANK\n",
        "plt.title(\"ACF of Standardized Residuals (EGARCH)\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5382f1ff",
      "metadata": {
        "id": "5382f1ff"
      },
      "source": [
        "Residual diagnostics are important to assess whether the EGARCH model has properly captured the dynamics in the return series, particularly autocorrelation and time-varying volatility. Interpret the above plot."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "091c412a",
      "metadata": {
        "id": "091c412a"
      },
      "source": [
        "### Step 6: Ljung-Box Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7b1cbb19",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "7b1cbb19",
        "outputId": "7cbc44b2-eae8-4128-8770-06d4db92eeec"
      },
      "outputs": [],
      "source": [
        "lb_test = ###COMPLETE THIS LINE\n",
        "print(lb_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8f7d013d",
      "metadata": {
        "id": "8f7d013d"
      },
      "source": [
        "The Ljung–Box test is used to detect autocorrelation in the residuals of a time series model. It tests the null hypothesis that the residuals are independently distributed up to a certain lag (in this case, lag 10). Interpret the results."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "534a88a3",
      "metadata": {
        "id": "534a88a3"
      },
      "source": [
        "### Step 7: Rolling Forecast (Expanding Window)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e913d976",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "id": "e913d976",
        "outputId": "78a0f927-c0e8-4470-f883-4675cf081963"
      },
      "outputs": [],
      "source": [
        "rolling_preds = []\n",
        "true_vals = []\n",
        "window = 1000\n",
        "\n",
        "for i in range(window, len(returns) - 1):\n",
        "    train = returns.iloc[:i]\n",
        "    test = returns.iloc[i + 1]\n",
        "\n",
        "    model = arch_model(train, __=____, _=_, _=_, ___='AR', lags=1, dist='t') ###FILL IN THE BLANKS\n",
        "    result = model.fit(disp='off')\n",
        "    forecast = result.forecast(horizon=1)\n",
        "    sigma = np.sqrt(forecast.variance.values[-1, 0])\n",
        "    rolling_preds.append(sigma)\n",
        "    true_vals.append(abs(test))\n",
        "\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.plot(returns.index[window + 1:], true_vals, label=\"|Actual Return|\")\n",
        "plt.plot(returns.index[window + 1:], rolling_preds, label=\"Forecast Volatility\")\n",
        "plt.legend()\n",
        "plt.title(\"Rolling Forecast: EGARCH(1,1)\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "92a05c6a",
      "metadata": {
        "id": "92a05c6a"
      },
      "source": [
        "Answer the following:\n",
        "1. What does the blue line represent?\n",
        "2. What does the orange line represent?\n",
        "\n",
        "Give an interprtation of the plot. For example, here's an interpretation on an EGARCH run on stock data:\n",
        "- The forecasted volatility generally tracks the magnitude of returns well, capturing periods of high and low volatility.\n",
        "- During volatile periods (e.g., mid-2022), the model forecasts higher volatility, while in calmer periods (e.g., mid-2023), it forecasts lower levels.\n",
        "- Although not every spike in return magnitude is captured exactly, the model reacts adaptively and reflects changing market conditions.\n",
        "- The EGARCH model effectively captures time-varying volatility and adjusts its forecasts as market conditions evolve. This dynamic behavior makes it a useful tool for risk management, Value at Risk (VaR), and volatility forecasting.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "23b9cd5d",
      "metadata": {
        "id": "23b9cd5d"
      },
      "source": [
        "### Step 8: Dynamic Value at Risk (VaR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e3474916",
      "metadata": {
        "id": "e3474916",
        "outputId": "2055d7c6-d78a-426c-d949-c89e847b200c"
      },
      "outputs": [],
      "source": [
        "from scipy.stats import t\n",
        "\n",
        "alpha = 0.05\n",
        "df = res2.params['nu']\n",
        "t_quant = t.ppf(alpha, df=df)\n",
        "\n",
        "VaR = res2.params['Const']  res2.conditional_volatility  t_quant ### ADD THE OPERATIONS TO THE LINE\n",
        "\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.plot(returns.index, returns, label=\"Returns\")\n",
        "plt.plot(returns.index, VaR, label=\"VaR (95%)\", color='red')\n",
        "plt.title(\"Dynamic VaR using EGARCH Model (95% Confidence)\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7127fafd",
      "metadata": {
        "id": "7127fafd"
      },
      "source": [
        "Note: In the financial world, Value at Risk (VaR) is a widely used risk metric that estimates the potential loss in value of a portfolio or asset over a given time horizon, at a specific confidence level.\n",
        "\n",
        "Answer the following:\n",
        "1. What does the blue line represent?\n",
        "2. What does the orange line represent?\n",
        "\n",
        "Give an interprtation of the plot and what it says about the EGARCH-based dynamic VaR model."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "35cfdaf0",
      "metadata": {
        "id": "35cfdaf0"
      },
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python (my_clean_env)",
      "language": "python",
      "name": "my_clean_env"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.21"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
