{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ebcec322",
   "metadata": {},
   "source": [
    "\n",
    "## Assignment 7 – Applied: Forecasting of Sales per Product Category\n",
    "**Week 7 Topic:** Tree-Based Methods – Decision Tree, Random Forest, and XGBoost  \n",
    "\n",
    "### Business Context\n",
    "Retailers rely on forecasting to optimize inventory and anticipate demand. In this assignment, you will forecast monthly sales per product category using tree-based ensemble learning techniques.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06ef21c",
   "metadata": {},
   "source": [
    "### Step 1: Load and Inspect the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13882e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "# TODO: Load dataset\n",
    "df = pd.read_csv('____')   ### FILL IN BLANK\n",
    "\n",
    "# TODO: Convert date column to datetime (day-first)\n",
    "df['____'] = pd.to_datetime(df['____'], dayfirst=True)   ### FILL IN BLANK\n",
    "\n",
    "# Display info\n",
    "print(df.info())\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915beba3",
   "metadata": {},
   "source": [
    "### Step 2: Data Preprocessing and Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5032ae33",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# TODO: Aggregate monthly sales by category\n",
    "df['Month'] = df['____'].dt.to_period('M')   ### FILL IN BLANK\n",
    "\n",
    "monthly_sales = df.groupby(['____', '____'])['____'].sum().reset_index()   ### FILL IN BLANKS\n",
    "\n",
    "monthly_sales['Month'] = monthly_sales['Month'].dt.to_timestamp()\n",
    "\n",
    "monthly_sales.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "688f7ad1",
   "metadata": {},
   "source": [
    "### Step 3: Prepare Features and Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c26b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "monthly_sales['Category_Code'] = le.fit_transform(monthly_sales['____'])   ### FILL IN BLANK\n",
    "\n",
    "X = monthly_sales[['____']]   ### FILL IN BLANK\n",
    "y = monthly_sales['____']   ### FILL IN BLANK\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=____, random_state=42)   ### FILL IN BLANK\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbecc585",
   "metadata": {},
   "source": [
    "### Step 4: Decision Tree Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905f87d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# TODO: Train Decision Tree model\n",
    "tree = DecisionTreeRegressor(random_state=____)   ### FILL IN BLANK\n",
    "tree.fit(____, ____)\n",
    "\n",
    "y_pred_tree = tree.predict(____)\n",
    "\n",
    "# Evaluate\n",
    "mae_tree = mean_absolute_error(____, ____)\n",
    "rmse_tree = np.sqrt(mean_squared_error(____, ____))\n",
    "r2_tree = r2_score(____, ____)\n",
    "\n",
    "print(\"Decision Tree - MAE:\", mae_tree, \"RMSE:\", rmse_tree, \"R2:\", r2_tree)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964f84ad",
   "metadata": {},
   "source": [
    "**Interpretation Question:** Which features does the tree rely on most for splitting, and why might this be useful for category-level sales trends?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84346a7",
   "metadata": {},
   "source": [
    "### Step 5: Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a884d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators=____, random_state=____)   ### FILL IN BLANKS\n",
    "rf.fit(____, ____)\n",
    "\n",
    "y_pred_rf = rf.predict(____)\n",
    "\n",
    "mae_rf = mean_absolute_error(____, ____)\n",
    "rmse_rf = np.sqrt(mean_squared_error(____, ____))\n",
    "r2_rf = r2_score(____, ____)\n",
    "\n",
    "print(\"Random Forest - MAE:\", mae_rf, \"RMSE:\", rmse_rf, \"R2:\", r2_rf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "855d1f9a",
   "metadata": {},
   "source": [
    "**Conceptual Question:** How does bagging help improve performance in Random Forests compared to a single Decision Tree?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af6c72f",
   "metadata": {},
   "source": [
    "### Step 6: XGBoost Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd6578d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "xgb = XGBRegressor(n_estimators=____, learning_rate=____, max_depth=____, random_state=____)   ### FILL IN BLANKS\n",
    "xgb.fit(____, ____)\n",
    "\n",
    "y_pred_xgb = xgb.predict(____)\n",
    "\n",
    "mae_xgb = mean_absolute_error(____, ____)\n",
    "rmse_xgb = np.sqrt(mean_squared_error(____, ____))\n",
    "r2_xgb = r2_score(____, ____)\n",
    "\n",
    "print(\"XGBoost - MAE:\", mae_xgb, \"RMSE:\", rmse_xgb, \"R2:\", r2_xgb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3ee5e1",
   "metadata": {},
   "source": [
    "**Reflection Question:** Why might boosting perform better on smaller datasets, and what role does the learning rate play in controlling model complexity?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b55852",
   "metadata": {},
   "source": [
    "### Step 7: Model Performance Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76a0a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "results = pd.DataFrame({\n",
    "    'Model': ['____', '____', '____'],\n",
    "    'MAE': [____, ____, ____],\n",
    "    'RMSE': [____, ____, ____],\n",
    "    'R2': [____, ____, ____]\n",
    "})\n",
    "results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c508b0b",
   "metadata": {},
   "source": [
    "### Step 8: Feature Importance Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b674942",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "importances = ____.feature_importances_   ### FILL IN BLANK\n",
    "plt.bar(['____'], importances, color='orange')   ### FILL IN BLANK\n",
    "plt.title('Feature Importance - Random Forest')\n",
    "plt.ylabel('Importance')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa2fabfc",
   "metadata": {},
   "source": [
    "### Step 9: Reflection and Discussion\n",
    "**Q1.** Which of the three models performed best, and why?  \n",
    "**Q2.** If additional variables (like Region, Segment, or Month) were added, how might model performance change?  \n",
    "**Q3.** In what types of business scenarios would you prioritize interpretability over accuracy?  \n",
    "**Q4.** How can tree-based methods assist managers in understanding key sales drivers?  \n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
